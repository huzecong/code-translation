random_seed: 1234

data:
  filename_pattern: "data/processed/{split}.txt"
  vocab_file: "data/vocab.vocab"
  encoding: "spm"
  verbose: true
  hparams:
    max_src_len: 512
    max_tgt_len: 512

model:
  hidden_dim: 512
  max_sentence_length: 512
  loss_label_confidence: 0.9

lr_scheduler:
  schedule: warmup
  init_lr: 0.0883  # 2 / sqrt(hidden_dim)
  warmup_steps: 16000

training:
  max_batch_tokens: 4096
  test_batch_size: 16

  max_train_steps: 100000
  display_steps: 500
  eval_steps: 5000

inference:
  beam_width: 5
  length_penalty: 0.6
