random_seed: 1234

data:
  filename_pattern: "data/processed/{split}.txt"
  vocab_file: "data/vocab.vocab"
  encoding: "spm"

model:
  hidden_dim: 512
  loss_label_confidence: 0.9

lr_scheduler:
  schedule: warmup
  init_lr: 0.0883  # 2 / sqrt(hidden_dim)
  warmup_steps: 16000

training:
  max_batch_tokens: 4096
  test_batch_size: 32

  max_train_steps: 100000
  display_steps: 500
  eval_steps: 2000

inference:
  beam_width: 5
  length_penalty: 0.6
