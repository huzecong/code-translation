random_seed: 19260817

data:
  training_set: "data/train.txt"
  valid_sets:
    default: "data/valid.txt"
  test_sets:
    default: "data/test.txt"
  vocab_file: "data/vocab.vocab"
  verbose: false
  hparams:
    token_delimiter: "\u0000"
    max_src_len: 512
    max_tgt_len: 512
    spm_model: "data/vocab.model"

model:
  hidden_dim: 512
  max_sentence_length: 512
  loss_label_confidence: 0.9
  num_encoder_layers: 6
  num_decoder_layers: 6

lr_scheduler:
  schedule: invsqrt
  lr: 0.0883
  warmup_steps: 16000

training:
  max_batch_tokens: 4096
  test_batch_size: 16

  max_train_steps: 2000000
  display_steps: 500
  eval_steps: 20000

inference:
  beam_width: 5
  length_penalty: 0.6
