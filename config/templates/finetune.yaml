lr_scheduler:
  schedule: invsqrt
  lr: 0.0001
  warmup_steps: 8000

training:
  max_batch_tokens: 2048
  max_train_steps: 20000
  eval_steps: 20000
  test_batch_size: 8

data:
  training_set: "data/train_extra.txt"
#  hparams:
#    max_src_len: 400
#    max_tgt_len: 400
